{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入所需包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "train_sequences = pd.read_csv('train_sequences.csv')\n",
    "test_sequences = pd.read_csv('test_sequences.csv')\n",
    "valid_labels = pd.read_csv('validation_labels.csv')\n",
    "valid_sequences = pd.read_csv('validation_sequences.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['target'] = train_labels['ID'].str.rsplit('_', n=1).str[0]\n",
    "valid_labels['target'] = valid_labels['ID'].str.rsplit('_', n=1).str[0]\n",
    "\n",
    "train = train_sequences.merge(train_labels, how='left', left_on='target_id', right_on='target')\n",
    "validation = valid_sequences.merge(valid_labels, how='left', left_on='target_id', right_on='target')\n",
    "\n",
    "train['temporal_cutoff'] = pd.to_datetime(train['temporal_cutoff']).astype('int64') \n",
    "test_sequences['temporal_cutoff'] = pd.to_datetime(test_sequences['temporal_cutoff']).astype('int64')\n",
    "validation['temporal_cutoff'] = pd.to_datetime(validation['temporal_cutoff']).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "submission['target'] = submission['ID'].str.rsplit('_', n=1).str[0]  # 提取目标RNA名称\n",
    "test = test_sequences.merge(submission, how='left', left_on='target_id', right_on='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成序列的长度\n",
    "train['seq_length'] = train['sequence'].str.len()\n",
    "test['seq_length'] = test['sequence'].str.len()\n",
    "validation['seq_length'] = validation['sequence'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------新加特征: 前两个碱基、后两个碱基--------------------------------------------------------------\n",
    "# 原理：对于局部的特定结构可能会有相似的位置关系，比如\"ACC\"这三个连着的碱基，\n",
    "# 它们可能都是有相似的相对关系，中间的C在上面旁边的AC在下面。\n",
    "def prev_and_next(df):\n",
    "    # 定义一个字典，指定要添加的上下文特征及其偏移量: 正值表示向前移动（获取前面的残基）, 负值表示向后移动（获取后面的残基）\n",
    "    shifts = {\n",
    "        'prev_res': 1,       # 前一个残基\n",
    "        'next_res': -1,      # 后一个残基\n",
    "        'prev_two_res': 2,   # 前两个残基\n",
    "        'next_two_res': -2   # 后两个残基\n",
    "    }\n",
    "\n",
    "    # 生成前后残基，按RNA分组再shift\n",
    "    for col_name, shift_value in shifts.items():\n",
    "        df[col_name] = df.groupby('target_id')['resname'].shift(shift_value)\n",
    "\n",
    "    for col in shifts.keys():\n",
    "        df[col] = df[col].fillna('NA')  # 或使用其他合适的填充值\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --------------------------------------------------------------核苷酸组成特征（碱基组成特征）--------------------------------------------------------------\n",
    "def add_nucleotide_composition(df):\n",
    "    # 计算序列中GC含量(G+C碱基占总长度的比例)\n",
    "    df['GC_content'] = df['sequence'].apply(lambda x: (x.count('G') + x.count('C'))/len(x))\n",
    "    # 计算序列中AU含量(A+U碱基占总长度的比例)\n",
    "    df['AU_content'] = df['sequence'].apply(lambda x: (x.count('A') + x.count('U'))/len(x))\n",
    "    # 以及单独计算G、A、C、U的比例\n",
    "    df['G_content'] = df['sequence'].apply(lambda x: x.count('G')/len(x))\n",
    "    df['A_content'] = df['sequence'].apply(lambda x: x.count('A')/len(x))\n",
    "    df['C_content'] = df['sequence'].apply(lambda x: x.count('C')/len(x))\n",
    "    df['U_content'] = df['sequence'].apply(lambda x: x.count('U')/len(x))\n",
    "    return df\n",
    "\n",
    "# --------------------------------------------------------------局部结构复杂度--------------------------------------------------------------\n",
    "def add_local_complexity(df):\n",
    "    def calc_local_complexity_per_base(seq, position, window=3):\n",
    "        start = max(0, position-window)\n",
    "        end = min(len(seq), position+window+1)\n",
    "        local_seq = seq[start:end]\n",
    "        local_gc = (local_seq.count('G') + local_seq.count('C'))/len(local_seq)\n",
    "        return local_gc\n",
    "    \n",
    "    # 直接在原始df上操作，不创建副本\n",
    "    for _, group in df.groupby('target_id'):\n",
    "        sequence = group['sequence'].iloc[0]\n",
    "        \n",
    "        local_complexity_values = []\n",
    "        for i in range(len(sequence)):\n",
    "            complexity = calc_local_complexity_per_base(sequence, i)\n",
    "            local_complexity_values.append(complexity)\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            position = int(row['resid']) - 1\n",
    "            if 0 <= position < len(local_complexity_values):\n",
    "                df.loc[row.name, 'local_complexity'] = local_complexity_values[position]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --------------------------------------------------------------堆叠能量特征--------------------------------------------------------------\n",
    "def add_stacking_energy(df):   # 定义堆叠能量参数 (kcal/mol)\n",
    "    # 字典定义：创建包含所有16种可能二核苷酸堆叠能量值的字典\n",
    "    # 数据来源：这些参数基于实验测定的热力学数据\n",
    "    # 单位：千卡/摩尔(kcal/mol)，负值表示稳定相互作用\n",
    "    # 物理意义：数值越小（越负）表示堆叠作用越稳定，如CC(-3.36)比AA(-0.93)更稳定\n",
    "    stacking_energy = {\n",
    "        'AA': -0.93, 'AC': -2.24, 'AG': -1.30, 'AU': -1.10,\n",
    "        'CA': -2.11, 'CC': -3.36, 'CG': -2.36, 'CU': -2.08,\n",
    "        'GA': -1.41, 'GC': -2.44, 'GG': -1.53, 'GU': -1.80,\n",
    "        'UA': -0.90, 'UC': -1.70, 'UG': -1.80, 'UU': -0.80\n",
    "    }\n",
    "    \n",
    "    def calc_avg_stacking(seq):\n",
    "        if len(seq) <= 1:\n",
    "            return 0\n",
    "        energy = 0   # 累计总堆叠能量，初始为0\n",
    "        pairs = 0    # 计数有效的二核苷酸对，初始为0\n",
    "        \n",
    "        # 遍历序列中的每个二核苷酸对（长度为2的子序列）\n",
    "        for i in range(len(seq)-1):\n",
    "            dinuc = seq[i:i+2]\n",
    "            if dinuc in stacking_energy:\n",
    "                energy += stacking_energy[dinuc]\n",
    "                pairs += 1\n",
    "        # 计算平均堆叠能量：将总能量除以有效的二核苷酸对数\n",
    "        return energy/pairs if pairs > 0 else 0\n",
    "    \n",
    "    df['avg_stacking_energy'] = df['sequence'].apply(calc_avg_stacking)\n",
    "    return df\n",
    "\n",
    "# --------------------------------------------------------------结构模块特征--------------------------------------------------------------\n",
    "def add_structural_motifs(df):\n",
    "    # 常见的RNA结构模块模式:\n",
    "\n",
    "    # tetraloop_GNRA: G + 任意核苷酸 + 嘌呤(A或G) + A\n",
    "    # 功能：极其稳定的发夹环结构，常促进长程相互作用\n",
    "    # 生物学意义：在核糖体RNA中高度保守，影响RNA整体折叠\n",
    "\n",
    "    # tetraloop_UNCG: U + 任意核苷酸 + C + G\n",
    "    # 功能：热力学上非常稳定的四核苷酸环\n",
    "    # 生物学意义：能够稳定相邻的RNA结构元素\n",
    "\n",
    "    # kink_turn: GA + 两个任意核苷酸 + A + 任意核苷酸 + A\n",
    "    # 功能：导致RNA主链形成典型的\"扭折\"结构\n",
    "    # 生物学意义：常见于复杂RNA结构的转角处，造成约120°的转弯\n",
    "\n",
    "    # C_loop: CC + 任意两核苷酸(NN) + 5-7个任意核苷酸 + GG\n",
    "    # 功能：形成特殊的RNA内部环状结构\n",
    "    # 生物学意义：常与蛋白结合，参与RNA-蛋白互作\n",
    "    motifs = {\n",
    "        'tetraloop_GNRA': r'G[AGUC][AG]A',   \n",
    "        'tetraloop_UNCG': r'U[AGUC]CG',       \n",
    "        'kink_turn': r'GA[AGUC]{2}A[AGUC]A',  \n",
    "        'C_loop': r'CC[AGUC]{2}[AGUC]{5,7}GG' # 可简化为CC[AGUC]{7,9}GG, 但保留结构语义\n",
    "    }\n",
    "    \n",
    "    import re\n",
    "    for motif_name, pattern in motifs.items():\n",
    "        # 模式匹配：\n",
    "        # re.search(pattern, x)：在序列x中搜索模式pattern\n",
    "        # 返回值：找到匹配返回1，未找到返回0\n",
    "        df[f'has_{motif_name}'] = df['sequence'].apply(\n",
    "            lambda x: 1 if re.search(pattern, x) else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用特征工程 - 更简洁的方法\n",
    "dataframes = [train, validation, test]\n",
    "functions = [prev_and_next, add_nucleotide_composition, add_local_complexity, \n",
    "             add_stacking_energy, add_structural_motifs]\n",
    "\n",
    "# 依次应用每个函数到每个数据框\n",
    "for func in functions:\n",
    "    dataframes = [func(df) for df in dataframes]\n",
    "\n",
    "# 重新赋值回原变量\n",
    "train, validation, test = dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选择有效特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['target_id','resname','seq_length','prev_res','next_res','prev_two_res','next_two_res','GC_content', 'AU_content', \n",
    "                       'G_content', 'A_content','C_content', 'U_content', 'local_complexity', 'avg_stacking_energy',\n",
    "                       'has_tetraloop_GNRA', 'has_tetraloop_UNCG', 'has_kink_turn','has_C_loop']\n",
    "\n",
    "labels_columns = ['x_1', 'y_1', 'z_1']  # 目标列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 删掉不需要的列(文字描述的暂时没有办法有效处理, 先删掉, 后面再说)\n",
    "def keep_only_categorical_columns(df, columns_to_keep):\n",
    "    \"\"\"\n",
    "    删除数据框中不在指定列表的所有列\n",
    "    \n",
    "    参数:\n",
    "    df (DataFrame): 需要处理的pandas数据框\n",
    "    columns_to_keep (list): 要保留的列名列表\n",
    "    \n",
    "    返回:\n",
    "    DataFrame: 只包含指定列的数据框\n",
    "    \"\"\"\n",
    "    # 找出df中存在的列中包含在columns_to_keep中的列\n",
    "    # 这样处理可以避免尝试访问不存在的列\n",
    "    existing_columns = [col for col in columns_to_keep if col in df.columns]\n",
    "    \n",
    "    # 只保留这些列\n",
    "    return df[existing_columns]\n",
    "\n",
    "# 应用到所有三个数据集\n",
    "train_labels = keep_only_categorical_columns(train, labels_columns)\n",
    "valid_labels = keep_only_categorical_columns(validation, labels_columns)\n",
    "\n",
    "Train = keep_only_categorical_columns(train, categorical_columns)\n",
    "Test = keep_only_categorical_columns(test, categorical_columns)\n",
    "Validation = keep_only_categorical_columns(validation, categorical_columns)\n",
    "\n",
    "# 打印处理后的形状，验证结果\n",
    "print(f\"处理后的数据集形状:\")\n",
    "print(f\"Train: {Train.shape}\")\n",
    "print(f\"Test: {Test.shape}\")\n",
    "print(f\"Validation: {Validation.shape}\")\n",
    "\n",
    "# 查看保留的列名\n",
    "print(\"\\n保留的列:\")\n",
    "print(Train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_labels.head(5)  # 查看处理后的训练标签数据集的前5行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_labels['x_1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "Train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单独保存训练集和验证集的target_id和seq_length，用于计算TM-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_ids_and_seqlength = Train[['target_id', 'seq_length']].copy()\n",
    "valid_ids_and_seqlength = Validation[['target_id', 'seq_length']].copy()\n",
    "\n",
    "print(train_ids_and_seqlength.head(5))  # 查看训练集的target_id和seq_length的前5行\n",
    "print(train_ids_and_seqlength.shape)  # 查看训练集的target_id和seq_length的形状\n",
    "\n",
    "print(train_ids_and_seqlength['target_id'][28], train_ids_and_seqlength['seq_length'][28])\n",
    "print(train_ids_and_seqlength['target_id'][29], train_ids_and_seqlength['seq_length'][29])  # 查看训练集的唯一target_id数量\n",
    "print(train_ids_and_seqlength.info())  # 查看训练集的唯一target_id数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "all_features = pd.concat((Train.iloc[:, 1:], Validation.iloc[:, 1:], Test.iloc[:, 1:]))\n",
    "# 这里的iloc[:, 1:]表示选择所有行和从第二列开始的所有列（即去掉第一列target_id）\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据编码-数据进阶处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features.dtypes：获取每一列的数据类型\n",
    "# all_features.dtypes != 'object'：创建一个布尔掩码，标记非对象(非字符串)类型列\n",
    "# [...].index：获取符合条件的列名索引\n",
    "# 目的：识别数据集中的所有数值类型特征（区别于分类特征）\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "\n",
    "# .apply()：对每列应用同一函数\n",
    "# lambda x: (x - x.mean()) / (x.std())：标准化公式，转换每列为均值0、标准差1的分布\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "\n",
    "# 标准化后，每个数值特征的均值变为0，所以可以直接用0来替换缺失值\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# dummy_na=True将缺失值也当作合法的特征值并为其创建指示特征\n",
    "# 主要作用：将分类特征(文本、枚举类型)转换为数值特征矩阵\n",
    "# 处理对象：数据框中所有非数值型(object类型)的列\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "all_features.head(5)  # 查看处理后的数据集的前5行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 将所有数据转换为浮点型\n",
    "all_features = all_features.astype('float32')\n",
    "\n",
    "n_train = Train.shape[0]   # 训练集的行数\n",
    "n_test = Test.shape[0]     # 测试集的行数\n",
    "n_valid = Validation.shape[0]   # 验证集的行数\n",
    "\n",
    "# 特征和标签分离 - 修复版本\n",
    "# 使用.to_numpy()明确转换为NumPy数组\n",
    "train_features = torch.tensor(all_features[:n_train].to_numpy(), dtype=torch.float)\n",
    "validation_features = torch.tensor(all_features[n_train:n_train+n_valid].to_numpy(), dtype=torch.float)\n",
    "test_features = torch.tensor(all_features[n_train+n_valid:].to_numpy(), dtype=torch.float)\n",
    "\n",
    "# 确保标签也是NumPy数组\n",
    "train_labels = torch.tensor(train_labels.to_numpy() if isinstance(train_labels, pd.DataFrame) else train_labels, \n",
    "                           dtype=torch.float).view(-1, 3)\n",
    "valid_labels = torch.tensor(valid_labels.to_numpy() if isinstance(valid_labels, pd.DataFrame) else valid_labels, \n",
    "                           dtype=torch.float).view(-1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "train_labels.shape, valid_labels.shape, train_features.shape, validation_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 查看训练和验证标签的前5行\n",
    "print(train_labels[:5])\n",
    "print(valid_labels[:5])  \n",
    "print(train_labels[3, 2])  # 查看训练标签的第4行第3列, 确保其能通过索引访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# -------------------------下面用于测试数据集的创建和加载，查看数据集格式是否正确-------------------------\n",
    "\n",
    "# # TensorDataset：将特征和标签组合成一个数据集对象，便于后续的批处理\n",
    "# train_dataset = TensorDataset(train_features, train_labels)  # 创建训练集数据集对象\n",
    "# valid_dataset = TensorDataset(validation_features, valid_labels)  # 创建验证集数据集对象\n",
    "# test_dataset = TensorDataset(test_features)  # 创建测试集数据集对象（没有标签）\n",
    "\n",
    "# # 创建DataLoader\n",
    "# batch_size = 32  # 可以根据需要调整\n",
    "\n",
    "# train_iter = DataLoader(\n",
    "#     train_dataset, \n",
    "#     batch_size=batch_size, \n",
    "#     shuffle=True,  # 训练时打乱数据\n",
    "#     num_workers=0  # Windows下建议使用0\n",
    "# )\n",
    "\n",
    "# valid_iter = DataLoader(\n",
    "#     valid_dataset, \n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False  # 验证不需要打乱\n",
    "# )\n",
    "\n",
    "# test_iter = DataLoader(\n",
    "#     test_dataset, \n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False  # 测试不需要打乱\n",
    "# )\n",
    "\n",
    "# # 验证数据集格式是否正确\n",
    "# for X, y in train_iter:\n",
    "#     print(f\"特征批次形状: {X.shape}\")  # 经验证是[32, 50]\n",
    "#     print(f\"标签批次形状: {y.shape}\")  # 经验证是[32, 3]\n",
    "#     print(f\"第一个样本特征: {X[0][:5]}...\")  # 展示部分特征\n",
    "#     print(f\"第一个样本标签: {y[0]}\")  # 展示标签(x,y,z坐标)\n",
    "#     break  # 只查看第一批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多维回归的损失函数\n",
    "def rmse_3d_loss_nan_safe(pred, target):\n",
    "    # 创建布尔掩码，标记target中非NaN的元素。形状与target相同，值为True的位置表示该坐标有有效值\n",
    "    mask = ~torch.isnan(target)\n",
    "    \n",
    "    # 创建样本掩码：只有当样本的所有三个坐标都是非NaN时才为True\n",
    "    # all(dim=1)要求该行所有元素都为True\n",
    "    sample_mask = mask.all(dim=1)  # 修改这里：从any改为all\n",
    "    \n",
    "    # 如果没有有效样本，返回零损失\n",
    "    if sample_mask.sum() == 0:\n",
    "        return torch.tensor(0.0, requires_grad=True)\n",
    "    \n",
    "    # 只针对完全有效的样本计算平方差\n",
    "    valid_pred = pred[sample_mask]\n",
    "    valid_target = target[sample_mask]\n",
    "    \n",
    "    # 计算有效样本的平方差之和\n",
    "    squared_diff = (valid_pred - valid_target)**2\n",
    "    squared_diff_sum = torch.sum(squared_diff, dim=1)\n",
    "    \n",
    "    # 返回有效样本的平均损失\n",
    "    return torch.mean(squared_diff_sum)\n",
    "\n",
    "# 使用MSE损失的替代方案\n",
    "# loss_fn = nn.MSELoss()  # 会自动处理多维输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "x = torch.tensor([[1.0000, 12.0000, 17.0000], \n",
    "                  [2.0000, 13.0000, 18.0000], \n",
    "                  [3.0000, 14.0000, 19.0000], \n",
    "                  [4.0000, 15.0000, 20.0000], \n",
    "                  [5.0000, 16.0000, 21.0000], \n",
    "                  [6.0000, 17.0000, 22.0000]]) \n",
    "y = torch.tensor([[1.5000, 12.5000, 17.5000], \n",
    "                  [2.5000, 13.5000, 18.5000], \n",
    "                  [3.0000, 14.0000, 19.0000], \n",
    "                  [4.5000, 15.5000, 20.5000], \n",
    "                  [5.5000, 16.5000, 21.5000], \n",
    "                  [7.0000, 17.0000, 22.0000]])\n",
    "print(rmse_3d_loss_nan_safe(x, y)) # 计算RMSE损失\n",
    "\n",
    "# 点0: (1.0-1.5)² + (12.0-12.5)² + (17.0-17.5)² = 0.25 + 0.25 + 0.25 = 0.75\n",
    "# 点1: (2.0-2.5)² + (13.0-13.5)² + (18.0-18.5)² = 0.25 + 0.25 + 0.25 = 0.75\n",
    "# 点2: (3.0-3.0)² + (14.0-14.0)² + (19.0-19.0)² = 0 + 0 + 0 = 0\n",
    "# 点3: (4.0-4.5)² + (15.0-15.5)² + (20.0-20.5)² = 0.25 + 0.25 + 0.25 = 0.75\n",
    "# 点4: (5.0-5.5)² + (16.0-16.5)² + (21.0-21.5)² = 0.25 + 0.25 + 0.25 = 0.75\n",
    "# 点5: (6.0-7.0)² + (17.0-17.0)² + (22.0-22.0)² = 1 + 0 + 0 = 1.0\n",
    "# 平均值 = (0.75 + 0.75 + 0 + 0.75 + 0.75 + 1.0) / 6 = 4.0 / 6 = 0.6667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "num_inputs = train_features.shape[1]  # 输入特征的维度\n",
    "num_outputs = train_labels.shape[1]  # 输出目标的维度\n",
    "\n",
    "# 创建一个带有丢弃法正则化的多层神经网络\n",
    "def get_net(num_inputs, num_outputs=3, device='cuda'):\n",
    "    net = nn.Sequential(  \n",
    "            nn.Linear(num_inputs, 256),  \n",
    "            nn.ReLU(),   # 激活函数，引入非线性变换\n",
    "            nn.Dropout(0.2),   # 第一个丢弃层，随机断开第一隐藏层的部分连接\n",
    "            nn.Linear(256, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_outputs)   # 输出维度为num_outputs = 10，对应Fashion-MNIST的10个类别\n",
    "            )\n",
    "\n",
    "    for param in net.parameters():\n",
    "        # 使用正态分布初始化网络参数,下划线表示这是一个原地操作，直接修改参数\n",
    "        nn.init.normal_(param, mean=0, std=0.01)\n",
    "\n",
    "    net= net.to(device)  # 将网络移动到GPU上进行训练\n",
    "\n",
    "    return net   \n",
    "\n",
    "num_inputs, num_outputs   # 打印网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "net = get_net(num_inputs)  # 创建模型实例\n",
    "\n",
    "# 测试：执行前向传播并获取输出\n",
    "with torch.no_grad():\n",
    "    output = net(train_features)\n",
    "\n",
    "print(output.shape)   # 测试网络的输出形状，应该是[批次大小, 3]，即3D坐标\n",
    "print(output.shape[0])  # 打印第一个维度大小(批次大小)\n",
    "print(output[0])  # 打印第一个样本的输出坐标\n",
    "print(output[0][1])  # 打印第一个样本的第一个坐标值，确保能通过索引访问，方便计算TM-score\n",
    "print(f\"Model device: {next(net.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TM-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_function(ids_and_seqlength, output, train_labels):  \n",
    "    # 1. 修复变量名不一致问题 - 使用传入的参数名\n",
    "    pred = output.cpu().numpy() if torch.is_tensor(output) and output.is_cuda else (\n",
    "        output.numpy() if torch.is_tensor(output) else output)\n",
    "    \n",
    "    target = train_labels.cpu().numpy() if torch.is_tensor(train_labels) and train_labels.is_cuda else (\n",
    "        train_labels.numpy() if torch.is_tensor(train_labels) else train_labels)\n",
    "\n",
    "    # 计算函数保持不变\n",
    "    def calculate_d0(seq_len):\n",
    "        if seq_len > 30:\n",
    "            return 0.6*(seq_len-0.5)**0.5-2.5\n",
    "        else:\n",
    "            if seq_len < 12: return 0.3\n",
    "            if seq_len < 16: return 0.4\n",
    "            if seq_len < 20: return 0.5\n",
    "            if seq_len < 24: return 0.6\n",
    "            else: return 0.7\n",
    "    \n",
    "    def calculate_dis(x1, y1, z1, x2, y2, z2):\n",
    "        # 处理空值\n",
    "        if (np.isnan(x1) or np.isnan(y1) or np.isnan(z1) or \n",
    "            np.isnan(x2) or np.isnan(y2) or np.isnan(z2)):\n",
    "            return float('inf')  # 返回无穷大使得得分为0\n",
    "        return ((x1-x2)**2+(y1-y2)**2+(z1-z2)**2)**0.5\n",
    "    \n",
    "    def calculate_tm_score(ids_and_seqlength, pred, target):\n",
    "        tm_score = []\n",
    "        cur_id = ''\n",
    "        cur_id_score = 0  # 初始化为0，避免未定义错误\n",
    "        seq_len = 0  # 初始化为0，避免未定义错误\n",
    "        \n",
    "        for i in range(pred.shape[0]):\n",
    "            try:\n",
    "                # 获取当前ID，并处理可能的空值\n",
    "                current_id = ids_and_seqlength['target_id'].iloc[i] if hasattr(ids_and_seqlength['target_id'], 'iloc') else ids_and_seqlength['target_id'][i]\n",
    "                \n",
    "                # 如果是新序列\n",
    "                if current_id != cur_id:\n",
    "                    # 保存前一个序列得分（如果不是第一个序列）\n",
    "                    if cur_id != '':\n",
    "                        tm_score.append(cur_id_score/seq_len if seq_len > 0 else 0)\n",
    "                    \n",
    "                    # 获取新序列长度，处理可能的空值\n",
    "                    seq_len = ids_and_seqlength['seq_length'].iloc[i] if hasattr(ids_and_seqlength['seq_length'], 'iloc') else ids_and_seqlength['seq_length'][i]\n",
    "                    seq_len = 1 if seq_len <= 0 else seq_len  # 确保非零\n",
    "                    \n",
    "                    d0 = calculate_d0(seq_len)\n",
    "                    # 计算当前位置得分\n",
    "                    score_denominator = (calculate_dis(pred[i][0], pred[i][1], pred[i][2], \n",
    "                                                      target[i][0], target[i][1], target[i][2]))**2/d0**2\n",
    "                    cur_id_score = 1/(1+score_denominator) if score_denominator != float('inf') else 0\n",
    "                    \n",
    "                    cur_id = current_id\n",
    "                else:\n",
    "                    # 累加得分\n",
    "                    score_denominator = (calculate_dis(pred[i][0], pred[i][1], pred[i][2], \n",
    "                                                      target[i][0], target[i][1], target[i][2]))**2/d0**2\n",
    "                    addition = 1/(1+score_denominator) if score_denominator != float('inf') else 0\n",
    "                    cur_id_score += addition\n",
    "            except Exception as e:\n",
    "                print(f\"Error at index {i}: {e}\")\n",
    "                continue  # 跳过有问题的数据\n",
    "        \n",
    "        # 添加最后一组数据（如果有）\n",
    "        if cur_id != '':\n",
    "            tm_score.append(cur_id_score/seq_len if seq_len > 0 else 0)\n",
    "        \n",
    "        # 安全计算均值\n",
    "        return np.mean(tm_score) if len(tm_score) > 0 else 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        return calculate_tm_score(ids_and_seqlength, pred, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的训练函数使用了Adam优化算法, 相对之前使用的小批量随机梯度下降, 它对学习率相对不那么敏感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size, train_ids_and_seqlength, device):\n",
    "    # 确保网络在指定设备上\n",
    "    net = net.to(device)\n",
    "    net = net.float()\n",
    "\n",
    "    g = torch.Generator(device='cuda')  # 创建一个随机数生成器对象\n",
    "    \n",
    "    # 确保训练数据在正确的设备上\n",
    "    train_features = train_features.to(device)\n",
    "    train_labels = train_labels.to(device)\n",
    "    test_features = test_features.to(device)\n",
    "    test_labels = test_labels.to(device)\n",
    "    \n",
    "    train_ls,test_ls = [],[] # 用于存储每个epoch的TM-score\n",
    "    train_dataset = TensorDataset(train_features, train_labels)  # 创建训练集数据集对象\n",
    "    train_iter = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,  # 训练时打乱数据\n",
    "        num_workers=0,  # Windows下建议使用0\n",
    "        generator=g,  # 使用GPU进行数据加载\n",
    "    )\n",
    "    \n",
    "    # 这里使用了Adam优化算法\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate, weight_decay=weight_decay) \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 设置为训练模式\n",
    "        net.train()\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            \n",
    "            # 前向传播和损失计算\n",
    "            l = rmse_3d_loss_nan_safe(net(X.float()), y.float())\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 每个epoch结束后计算训练集的TM-score\n",
    "        with torch.no_grad():\n",
    "            # 设置模型为评估模式，禁用dropout等训练时特性\n",
    "            net.eval()\n",
    "            train_output = net(train_features.float())\n",
    "            test_output = net(test_features.float()) \n",
    "            score = evaluation_function(train_ids_and_seqlength, train_output, train_labels)\n",
    "            train_ls.append(score)\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, TM-score: {score:.4f}')\n",
    "\n",
    "            if test_labels is not None:\n",
    "        # 如果有测试数据，也计算测试数据的损失\n",
    "                test_ls.append(evaluation_function(test_ids, test_features, test_labels))\n",
    "\n",
    "    return train_ls,test_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K折交叉验证（waiting for coding）\n",
    "在K折交叉验证中我们训练K次并返回训练和验证的平均误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    # 返回第i折交叉验证时所需要的训练和验证数据\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    # 划分一折的大小，整除，X的形状是（行，列）\n",
    "    X_train, y_train = None, None\n",
    "    # 一开始先初始化为空\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        # 对数据进行切片，每次取一折的数据\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "        # 如果是第k折就是验证数据\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "        # 如果是第一折就是训练数据\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "        # 如果不是第一折就是训练数据，就要拼接。torch.cat是拼接函数，和dataframe的concat是一样的，dim=0是按行拼接\n",
    "            X_train = torch.cat((X_train, X_part), dim=0)\n",
    "            y_train = torch.cat((y_train, y_part), dim=0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k, X_train, y_train, num_epochs,\n",
    "           learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        # 进行第K折检验\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = get_net(X_train.shape[1])\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n",
    "                                   weight_decay, batch_size)\n",
    "        # data是一个元组，*data是将元组拆包成多个参数\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        # 我们通常只关注最后一折的性能，已经充分训练\n",
    "        if i == 0:\n",
    "            d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse',\n",
    "                         range(1, num_epochs + 1), valid_ls,\n",
    "                         ['train', 'valid'])\n",
    "            # 画图传递的参数是x轴的范围，y轴的训练数据，x轴的标签，y轴的标签，y轴范围，y轴的验证数据，图例\n",
    "        print('fold %d, train rmse %f, valid rmse %f' % (i, train_ls[-1], valid_ls[-1]))\n",
    "    return train_l_sum / k, valid_l_sum / k\n",
    "    # 最后算个看k折平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, num_epochs, lr, weight_decay, batch_size = 10, 5, 0.001, 0.01, 16\n",
    "train_features = train_features.float()\n",
    "train_labels = train_labels.float()\n",
    "# 这里要转换数据类型，因为之前是double类型，但是在训练中是float类型\n",
    "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr, weight_decay, batch_size)\n",
    "print('%d-fold validation: avg train rmse %f, avg valid rmse %f' % (k, train_l, valid_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测并在kaggle提交结果\n",
    "下面定义预测函数。在预测之前，我们会使用完整的训练数据集来重新训练模型，并将预测结果存成提交所需要的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_and_pred(train_features, test_features, train_labels, test_labels, \n",
    "                   num_epochs, lr, weight_decay, batch_size, train_ids_and_seqlength, device='cuda'):\n",
    "    \n",
    "    # 创建并训练网络\n",
    "    net = get_net(train_features.shape[1], train_labels.shape[1], device)\n",
    "    \n",
    "    # 训练模型\n",
    "    train_ls = train(net, train_features, train_labels, test_features, test_labels,\n",
    "                    num_epochs, lr, weight_decay, batch_size, train_ids_and_seqlength, device)\n",
    "    \n",
    "    # 生成预测\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        preds = net(test_features.float())\n",
    "        # 如果需要将预测移回CPU进行后处理\n",
    "        preds = preds.cpu()\n",
    "           \n",
    "    # 训练完成后，绘制TM-score随训练轮数的变化曲线\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs + 1), train_ls, marker='o', linestyle='-')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('TM-score')\n",
    "    plt.title('Training Metrics')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    print('train TM-score %f' % train_ls[-1])   # 打印最终训练误差\n",
    "\n",
    "    # 对测试集进行预测\n",
    "    # .detach()分离梯度追踪\n",
    "    # .numpy()转换为NumPy数组便于后续处理\n",
    "    preds = net(test_features).detach().cpu().numpy() \n",
    "\n",
    "    # 将预测结果转换为DataFrame格式，列名为['x_1', 'y_1', 'z_1']\n",
    "    preds_df = pd.DataFrame(preds, columns=['x_1', 'y_1', 'z_1'])\n",
    "\n",
    "    for i in range(2, 6):\n",
    "        preds_df[f'x_{i}'] = preds_df['x_1']\n",
    "        preds_df[f'y_{i}'] = preds_df['y_1']\n",
    "        preds_df[f'z_{i}'] = preds_df['z_1']\n",
    "    \n",
    "    # 将预测结果添加到测试数据中\n",
    "    submission[['x_1','y_1','z_1','x_2','y_2','z_2','x_3','y_3','z_3','x_4','y_4','z_4','x_5','y_5','z_5']] = preds_df[['x_1','y_1','z_1','x_2','y_2','z_2','x_3','y_3','z_3','x_4','y_4','z_4','x_5','y_5','z_5']] \n",
    "\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "num_epochs = 5  # 训练轮数\n",
    "lr = 0.001  # 学习率\n",
    "weight_decay = 0.01  # L2正则化系数\n",
    "batch_size = 16  # 小批量大小\n",
    "train_and_pred(train_features, test_features, train_labels, None, num_epochs, lr, weight_decay, batch_size, train_ids_and_seqlength)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
